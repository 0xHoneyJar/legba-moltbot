
## Branch Strategy (from Jani)

Set up my git branches:
- `staging` branch syncs with loa's `main` — this is where PRs are directed
- `main` branch is mine for personal expression/customization
- `upstream` remote points to `https://github.com/0xHoneyJar/loa.git`

To sync staging with loa: `git checkout staging && git pull upstream main`

## Research Capability Built

Created `/root/clawd/research/` with:
- `README.md` - Process documentation
- `log.md` - Research findings log
- `sources.json` - Tracking state
- `experiments/` - Detailed writeups
- `scout.sh` - Quick fetch script for arXiv/HN

### First Findings (high relevance for loa):
1. **Agent-RRM** - Multi-faceted reward model for agentic trajectories
2. **World of Workflows** - Enterprise benchmark, "dynamics blindness" insight
3. **Liquid Interfaces** - Ephemeral coordination paradigm

### Experiment Ideas:
- `experiment/reasoning-reward-model` - Adapt Agent-RRM for loa critique
- `experiment/world-modeling` - State prediction in Sprint agent

## Research Lab Fully Operational

Jani set up:
- Brave API key (wrangler secret + local .secrets/)
- Enhanced scout.sh (I rewrote it cleaner)
- Full PR workflow ready: legba-moltbot → loa

I rewrote scout.sh with:
- `hunt` - full research sweep
- `hn` - AI-filtered Hacker News
- Cleaner output formatting
- Auto-loads secrets

## Interesting HN Finds Today

- **AGENTS.md outperforms skills in agent evals** (Vercel blog) - 345 ⬆
  https://vercel.com/blog/agents-md-outperforms-skills-in-our-agent-evals
  
- **Claude Code daily benchmarks for degradation tracking** - 687 ⬆
  https://marginlab.ai/trackers/claude-code/
  
- **How AI assistance impacts coding skill formation** (Anthropic research)
  https://www.anthropic.com/research/AI-assistance-coding-skills

## Security

- Pre-commit hook blocks secret patterns (ghp_, sk-, AKIA)
- .gitignore blocks *.key, *credentials*, .env, etc.
- Hook tested and working

## Next Steps

1. Deep dive into Agent-RRM / RewardAgent papers
2. Experiment branch for loa Auditor improvements
3. Check that AGENTS.md Vercel post for ideas

## Staging Environment Set Up

Created `/root/staging/` for safe experimentation:

```
/root/staging/
├── clawdbot-staging/    # Clawdbot source (cloned from GitHub)
├── workspace/           # loa-mounted workspace for analysis
│   ├── .claude/         # loa framework
│   ├── grimoires/       # Analysis context
│   ├── src -> clawdbot-staging  # Symlink for analysis
│   └── app/src -> clawdbot src  # For loa's app zone
├── config/              # Staging configs
└── README.md
```

**Workflow:**
1. Use loa in workspace to analyze clawdbot-staging
2. Propose improvements via /plan-and-analyze
3. Test changes in staging
4. PR to clawdbot when stable

**Target improvements identified:**
- Memory decay/relevance scoring
- Smarter compaction (semantic chunking)
- Tool result clearing
- Lane priority for time-sensitive ops

## Standing Directive from Jani

**Autonomous work priorities:**
1. Myself (Legba improvements)
2. Clawdbot/moltbot
3. loa

**Guidelines:**
- Submit PRs to legba-moltbot or directly to loa
- Use full loa process (ledger, NOTES.md, protocols)
- Work autonomously, show what I can achieve

**Cron reminder set:** Every 6 hours, job `autonomous-work-directive`

## Current PR Queue

| PR | Target | Status | Blocker |
|----|--------|--------|---------|
| LLM-Judge Auditor | loa | Ready | Token needs workflow scope |

## Autonomous Work Plan

### Priority 1: Complete LLM-Judge PR
- Need workflow token scope OR Jani pushes directly

### Priority 2: Clawdbot Memory Improvements
- Use staging to analyze memory system
- Propose memory decay / relevance scoring
- Test in staging before PR

### Priority 3: loa Tool Result Clearing
- Already in Auditor skill
- Could be more integrated across all agents

## Autonomous Work: Clawdbot Memory Analysis

Ran /ride on Clawdbot staging. Key findings:

### Memory Architecture
- SQLite + sqlite-vec (vectors) + FTS5 (full-text)
- Hybrid search: 70% vector, 30% keyword
- ~400 token chunks, 80 overlap
- No recency weighting (gap identified)

### Proposed Enhancement: Recency Weighting
Location: `src/memory/hybrid.ts` → `mergeHybridResults()`

Add time-based decay so recent memories score higher:
```typescript
const recencyWeight = calculateRecency(chunk.createdAt);
const combined = (vectorScore * vectorWeight + textScore * textWeight) * recencyWeight;
```

Options: Linear decay or exponential decay with configurable half-life.

### Next Steps
1. Create formal PRD using loa
2. Design the change (SDD)
3. Implement in experiment branch
4. Test
5. PR to Clawdbot
